{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Grace's Projects\\ezproperty\\db\n",
      "c:\\Grace's Projects\\ezproperty\n",
      "Connecting to 'localhost' with user 'root'\n",
      "Database | Using database is3107g6.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "\n",
    "from warehouse import DataWarehouse\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "from db.etl import MultilayerPerceptronPipeline\n",
    "\n",
    "pipe = MultilayerPerceptronPipeline()\n",
    "schema_name = 'ml__MultiLayerPerceptron'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to 'localhost' with user 'root'\n",
      "Database | Using database is3107g6.\n",
      "Database | Query executed successfully.\n",
      "      district  floorRangeStart  floorRangeEnd  area  transactionDate  resale  \\\n",
      "4995       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
      "4996       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
      "4997       3.0              6.0           10.0  1.40         0.999336     0.0   \n",
      "4998       3.0             21.0           25.0  1.06         0.665311     0.0   \n",
      "4999       3.0             26.0           30.0  1.06         0.665311     0.0   \n",
      "\n",
      "      price  \n",
      "4995  2.273  \n",
      "4996  2.245  \n",
      "4997  4.110  \n",
      "4998  3.240  \n",
      "4999  3.280  \n",
      "district           float64\n",
      "floorRangeStart    float64\n",
      "floorRangeEnd      float64\n",
      "area               float64\n",
      "transactionDate    float64\n",
      "resale             float64\n",
      "price              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "db = DataWarehouse()\n",
    "\n",
    "dataset = db.query('''\n",
    "    SELECT district, floorRangeStart, floorRangeEnd, area, transactionDate, resale, price FROM main__PropertyTransaction\n",
    "    LIMIT 5000\n",
    "''')\n",
    "\n",
    "\n",
    "# Data pre-processing to convert all to float and standardise magnitude\n",
    "df = pd.DataFrame(dataset)\n",
    "for column in df.columns:\n",
    "    if column == \"transactionDate\":\n",
    "        df[column] = pd.to_datetime(df[column])\n",
    "        df[column] = (df[column].max() - df[column]) / np.timedelta64(1,'Y')\n",
    "    if column == \"price\": # price is in millions\n",
    "        df[column] = df[column].astype(float) / 1e6\n",
    "    if column == \"area\": # area is in 100 square feet\n",
    "        df[column] = df[column].astype(float) / 100\n",
    "    else:\n",
    "        df[column] = df[column].astype(float)\n",
    "print(df.tail())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 6) (500, 6) (4500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "train = df.sample(frac=0.9,random_state=200)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "X_train, Y_train = train[[column for column in df.columns if column != 'price']], train['price']\n",
    "X_test, Y_test = test[[column for column in df.columns if column != 'price']], test['price']\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                448       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,875\n",
      "Trainable params: 8,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "def build_mlp_model():\n",
    "  model = keras.Sequential()\n",
    "  model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  return model\n",
    "\n",
    "mlp_model = build_mlp_model()\n",
    "mlp_model.summary()\n",
    "\n",
    "# Build model\n",
    "# def build_mlp_model():\n",
    "#   model = keras.Sequential()\n",
    "#   model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(4, activation='relu'))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(4, activation='relu'))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(1, activation='linear'))\n",
    "#   return model\n",
    "\n",
    "# mlp_model = build_mlp_model()\n",
    "# mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "# mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "# mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 1s 908us/step - loss: 0.9173 - mae: 0.9173\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 0s 876us/step - loss: 0.6801 - mae: 0.6801\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 0s 879us/step - loss: 0.6115 - mae: 0.6115\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 0s 881us/step - loss: 0.5985 - mae: 0.5985\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 0s 899us/step - loss: 0.5441 - mae: 0.5441\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 0s 896us/step - loss: 0.5365 - mae: 0.5365\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 0s 965us/step - loss: 0.5196 - mae: 0.5196\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 0s 881us/step - loss: 0.5126 - mae: 0.5126\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 0s 905us/step - loss: 0.4824 - mae: 0.4824\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 0s 878us/step - loss: 0.4754 - mae: 0.4754\n"
     ]
    }
   ],
   "source": [
    "mlp_history = mlp_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4322 - mae: 0.4322\n",
      "(500, 6)\n",
      "test loss is 0.4321804940700531\n",
      "test accuracy is 0.4321804940700531\n"
     ]
    }
   ],
   "source": [
    "loss, acc = mlp_model.evaluate(X_test, Y_test)\n",
    "print(X_test.shape)\n",
    "print(f'test loss is {loss}')\n",
    "print(f'test accuracy is {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n"
     ]
    }
   ],
   "source": [
    "def export_model():\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n"
     ]
    }
   ],
   "source": [
    "def save_model_to_db():\n",
    "\n",
    "    #pickling the model\n",
    "    pickled_model = pickle.dumps(mlp_model)\n",
    "    \n",
    "\n",
    "    # creating other attributes\n",
    "    model = [{ \"model\": pickled_model, 'name': \"MLP\", 'created_time': time.time()}]\n",
    "    pipe.dl_loader(model, schema_name)\n",
    "\n",
    "save_model_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 3 documents.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     pred_price \u001b[39m=\u001b[39m model(\u001b[39m3.0\u001b[39m, \u001b[39m6.0\u001b[39m, \u001b[39m10.0\u001b[39m, \u001b[39m1.06\u001b[39m, \u001b[39m1.579772\u001b[39m, \u001b[39m0.0\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(pred_price)\n\u001b[1;32m---> 15\u001b[0m load_model_to_db()\n",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m, in \u001b[0;36mload_model_to_db\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m result \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mdl_getter(\u001b[39m'\u001b[39m\u001b[39mml__MultiLayerPerceptron\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# print(result)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# print(result[0][\"model\"])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# pickled_model = json_data[result[0][\"model\"]]\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mloads(result[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m     11\u001b[0m pred_price \u001b[39m=\u001b[39m model(\u001b[39m3.0\u001b[39m, \u001b[39m6.0\u001b[39m, \u001b[39m10.0\u001b[39m, \u001b[39m1.06\u001b[39m, \u001b[39m1.579772\u001b[39m, \u001b[39m0.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\saving\\pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39mload_model(filepath, safe_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\saving\\pickle_utils.py:46\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     40\u001b[0m         f\u001b[39m.\u001b[39mwrite(serialized_model)\n\u001b[0;32m     41\u001b[0m     \u001b[39m# When loading, direct import will work for most custom objects\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[39m# though it will require get_config() to be implemented.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[39m# Some custom objects (e.g. an activation in a Dense layer,\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[39m# serialized as a string by Dense.get_config()) will require\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[39m# a custom_object_scope.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39;49mload_model(filepath, safe_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\saving\\saving_lib.py:277\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    274\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    276\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\saving\\saving_lib.py:242\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 242\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[0;32m    243\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    246\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\saving\\serialization_lib.py:508\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     compile_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompile_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m compile_config:\n\u001b[1;32m--> 508\u001b[0m         instance\u001b[39m.\u001b[39;49mcompile_from_config(compile_config)\n\u001b[0;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[0;32m    511\u001b[0m     record_object_after_deserialization(\n\u001b[0;32m    512\u001b[0m         instance, config[\u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    513\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\engine\\training.py:3392\u001b[0m, in \u001b[0;36mModel.compile_from_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   3389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[0;32m   3390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m   3391\u001b[0m     \u001b[39m# Create optimizer variables.\u001b[39;00m\n\u001b[1;32m-> 3392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:984\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hyper:\n\u001b[0;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_hyper(name)\n\u001b[1;32m--> 984\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Grace's Projects\\ezproperty\\env\\lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:974\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n\u001b[0;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[39m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_hyper\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "def load_model_to_db():\n",
    "    json_data = {}\n",
    "\n",
    "    result = pipe.dl_getter('ml__MultiLayerPerceptron')\n",
    "    # print(result)\n",
    "    # print(result[0][\"model\"])\n",
    "    # pickled_model = json_data[result[0][\"model\"]]\n",
    "    model = pickle.loads(result[0][\"model\"])\n",
    "    print(model)\n",
    "\n",
    "    pred_price = model(3.0, 6.0, 10.0, 1.06, 1.579772, 0.0)\n",
    "\n",
    "    print(pred_price)\n",
    "\n",
    "load_model_to_db()\n",
    " \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b996d74428cb98fb363d931233fbb38b0ce88b2e0e1a2ea6a636f62c3ef3ff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
