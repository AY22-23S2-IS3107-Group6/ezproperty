{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "--rnRL8WqNcl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Grace's Projects\\ezproperty\\db\n",
            "c:\\Grace's Projects\\ezproperty\n",
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Loading 0 documents to data lake.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n"
          ]
        }
      ],
      "source": [
        "# Provided: notebook bootstrapping\n",
        "# Keras Models\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "\n",
        "# # Aditional Libs\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path) \n",
        "\n",
        "from warehouse import DataWarehouse\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('../..'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path) \n",
        "from db.etl import MultilayerPerceptronPipeline\n",
        "\n",
        "pipe = MultilayerPerceptronPipeline()\n",
        "schema_name = 'ml__MultiLayerPerceptron'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2tX966Pp3RJ",
        "outputId": "de61e052-3a68-4dbb-d897-967d57503b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Database | Query executed successfully.\n",
            "      district  floorRangeStart  floorRangeEnd  area  transactionDate  resale  \\\n",
            "4995       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
            "4996       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
            "4997       3.0              6.0           10.0  1.40         0.999336     0.0   \n",
            "4998       3.0             21.0           25.0  1.06         0.665311     0.0   \n",
            "4999       3.0             26.0           30.0  1.06         0.665311     0.0   \n",
            "\n",
            "      price  \n",
            "4995  2.273  \n",
            "4996  2.245  \n",
            "4997  4.110  \n",
            "4998  3.240  \n",
            "4999  3.280  \n",
            "district           float64\n",
            "floorRangeStart    float64\n",
            "floorRangeEnd      float64\n",
            "area               float64\n",
            "transactionDate    float64\n",
            "resale             float64\n",
            "price              float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "db = DataWarehouse()\n",
        "\n",
        "dataset = db.query('''\n",
        "    SELECT district, floorRangeStart, floorRangeEnd, area, transactionDate, resale, price FROM main__PropertyTransaction\n",
        "    LIMIT 5000\n",
        "''')\n",
        "\n",
        "\n",
        "# Data pre-processing to convert all to float and standardise magnitude\n",
        "df = pd.DataFrame(dataset)\n",
        "for column in df.columns:\n",
        "    if column == \"transactionDate\":\n",
        "        df[column] = pd.to_datetime(df[column])\n",
        "        df[column] = (df[column].max() - df[column]) / np.timedelta64(1,'Y')\n",
        "    if column == \"price\": # price is in millions\n",
        "        df[column] = df[column].astype(float) / 1e6\n",
        "    if column == \"area\": # area is in 100 square feet\n",
        "        df[column] = df[column].astype(float) / 100\n",
        "    else:\n",
        "        df[column] = df[column].astype(float)\n",
        "print(df.tail())\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7JpSZnuqNcm",
        "outputId": "dff17f3e-814f-4ced-ddc5-87ae9d681309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4500, 6) (500, 6) (4500,) (500,)\n"
          ]
        }
      ],
      "source": [
        "train = df.sample(frac=0.9,random_state=200)\n",
        "test = df.drop(train.index)\n",
        "\n",
        "X_train, Y_train = train[[column for column in df.columns if column != 'price']], train['price']\n",
        "X_test, Y_test = test[[column for column in df.columns if column != 'price']], test['price']\n",
        "\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsmgfY4FwjK1",
        "outputId": "d3595f59-b714-44c2-cc4e-57ee672502a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                448       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,875\n",
            "Trainable params: 8,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build model\n",
        "def build_mlp_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  return model\n",
        "\n",
        "mlp_model = build_mlp_model()\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZINq9ljyxOIh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeAeh1lzTud3",
        "outputId": "3fa691cb-dac9-43dd-bd3e-d6463874933d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "282/282 [==============================] - 1s 1ms/step - loss: 0.9316 - mae: 0.9316\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.7563 - mae: 0.7563\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.7081 - mae: 0.7081\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 0s 962us/step - loss: 0.6237 - mae: 0.6237\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.5556 - mae: 0.5556\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.5107 - mae: 0.5107\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 0s 983us/step - loss: 0.5072 - mae: 0.5072\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.4884 - mae: 0.4884\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.5001 - mae: 0.5001\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.4852 - mae: 0.4852\n"
          ]
        }
      ],
      "source": [
        "mlp_history = mlp_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQ0LWQXVzU-",
        "outputId": "dda7cdd3-9dc8-4b4e-8501-2bf0b2de2ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 968us/step - loss: 0.4674 - mae: 0.4674\n",
            "(500, 6)\n",
            "test loss is 0.46735242009162903\n",
            "test accuracy is 0.46735242009162903\n"
          ]
        }
      ],
      "source": [
        "loss, acc = mlp_model.evaluate(X_test, Y_test)\n",
        "print(X_test.shape)\n",
        "print(f'test loss is {loss}')\n",
        "print(f'test accuracy is {acc}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n"
          ]
        }
      ],
      "source": [
        "def save_model_to_db():\n",
        "\n",
        "    #pickling the model\n",
        "    pickled_model = pickle.dumps(mlp_model)\n",
        "    \n",
        "    # creating other attributes\n",
        "    model = [{ \"model\": pickled_model, 'name': \"MLP\", 'created_time': time.time()}]\n",
        "    pipe.dl_loader(model, schema_name)\n",
        "\n",
        "save_model_to_db()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n",
            "<keras.engine.sequential.Sequential object at 0x0000019F851F4940>\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "[[2.1240528]]\n"
          ]
        }
      ],
      "source": [
        "def load_from_db_and_predict(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale):\n",
        "    json_data = {}\n",
        "\n",
        "    result = pipe.dl_getter('ml__MultiLayerPerceptron')\n",
        "    model = pickle.loads(result[0][\"model\"])\n",
        "    print(model)\n",
        "\n",
        "    input_data  = np.array([[district, floorRangeStart, floorRangeEnd, area, transactionDate, resale]])\n",
        "    pred_price = model.predict(input_data)\n",
        "    print(pred_price)\n",
        "\n",
        "load_from_db_and_predict(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale)    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "9b996d74428cb98fb363d931233fbb38b0ce88b2e0e1a2ea6a636f62c3ef3ff6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
