{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keith/Desktop/NUS/Y2S2/IS3107/Project/ezproperty/db\n",
      "/Users/keith/Desktop/NUS/Y2S2/IS3107/Project/ezproperty\n",
      "Connecting to 'localhost' with user 'root'\n",
      "Database | Using database is3107g6.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n",
      "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import sklearn\n",
    "import joblib\n",
    "# import gridfs\n",
    "# from gridfs import GridFS\n",
    "# import io\n",
    "from bson.binary import Binary\n",
    "from bson import ObjectId\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "\n",
    "from warehouse import DataWarehouse\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "from db.etl import MultilayerPerceptronPipeline\n",
    "\n",
    "pipe = MultilayerPerceptronPipeline()\n",
    "schema_name = 'ml__MultiLayerPerceptron'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to 'localhost' with user 'root'\n",
      "Database | Using database is3107g6.\n",
      "Database | Query executed successfully.\n",
      "      district  floorRangeStart  floorRangeEnd  area  transactionDate  resale  \\\n",
      "4995       3.0              6.0           10.0  1.06         1.579772     0.0   \n",
      "4996       3.0             16.0           20.0  0.76         1.579772     0.0   \n",
      "4997       3.0             21.0           25.0  1.16         1.579772     0.0   \n",
      "4998       3.0              1.0            5.0  1.16         1.579772     0.0   \n",
      "4999       3.0             11.0           15.0  1.59         1.579772     0.0   \n",
      "\n",
      "        price  \n",
      "4995  2.84946  \n",
      "4996  2.25270  \n",
      "4997  3.30000  \n",
      "4998  3.05700  \n",
      "4999  4.26430  \n",
      "district           float64\n",
      "floorRangeStart    float64\n",
      "floorRangeEnd      float64\n",
      "area               float64\n",
      "transactionDate    float64\n",
      "resale             float64\n",
      "price              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "db = DataWarehouse()\n",
    "\n",
    "dataset = db.query('''\n",
    "    SELECT district, floorRangeStart, floorRangeEnd, area, transactionDate, resale, price FROM main__PropertyTransaction\n",
    "    LIMIT 5000\n",
    "''')\n",
    "\n",
    "\n",
    "# Data pre-processing to convert all to float and standardise magnitude\n",
    "df = pd.DataFrame(dataset)\n",
    "for column in df.columns:\n",
    "    if column == \"transactionDate\":\n",
    "        df[column] = pd.to_datetime(df[column])\n",
    "        df[column] = (df[column].max() - df[column]) / np.timedelta64(1,'Y')\n",
    "    if column == \"price\": # price is in millions\n",
    "        df[column] = df[column].astype(float) / 1e6\n",
    "    if column == \"area\": # area is in 100 square feet\n",
    "        df[column] = df[column].astype(float) / 100\n",
    "    else:\n",
    "        df[column] = df[column].astype(float)\n",
    "print(df.tail())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 6) (500, 6) (4500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "train = df.sample(frac=0.9,random_state=200)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "X_train, Y_train = train[[column for column in df.columns if column != 'price']], train['price']\n",
    "X_test, Y_test = test[[column for column in df.columns if column != 'price']], test['price']\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_77 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 64)                448       \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,875\n",
      "Trainable params: 8,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "def build_mlp_model():\n",
    "  model = keras.Sequential()\n",
    "  model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  return model\n",
    "\n",
    "mlp_model = build_mlp_model()\n",
    "mlp_model.summary()\n",
    "\n",
    "# Build model\n",
    "# def build_mlp_model():\n",
    "#   model = keras.Sequential()\n",
    "#   model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(4, activation='relu'))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(4, activation='relu'))\n",
    "#   # model.add(Dropout(0.1))\n",
    "#   model.add(Dense(1, activation='linear'))\n",
    "#   return model\n",
    "\n",
    "# mlp_model = build_mlp_model()\n",
    "# mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "mlp_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "# mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "# mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.7102 - mae: 0.7102\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4813 - mae: 0.4813\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4656 - mae: 0.4656\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4568 - mae: 0.4568\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4454 - mae: 0.4454\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4348 - mae: 0.4348\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4433 - mae: 0.4433\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4424 - mae: 0.4424\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4288 - mae: 0.4288\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.4272 - mae: 0.4272\n"
     ]
    }
   ],
   "source": [
    "mlp_history = mlp_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3825 - mae: 0.3825\n",
      "(500, 6)\n",
      "test loss is 0.38253888487815857\n",
      "test accuracy is 0.38253888487815857\n"
     ]
    }
   ],
   "source": [
    "loss, acc = mlp_model.evaluate(X_test, Y_test)\n",
    "print(X_test.shape)\n",
    "print(f'test loss is {loss}')\n",
    "print(f'test accuracy is {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_db():\n",
    "\n",
    "    #pickling the model\n",
    "    pickled_model = pickle.dumps(mlp_model)\n",
    "\n",
    "    # using joblib\n",
    "    joblib.dump(mlp_model, \"test\")\n",
    "\n",
    "    \n",
    "    # pickled_model = tf.keras.models.save_model(mlp_model, 'my_model.h5')\n",
    "    # model_file = 'my_model.h5'\n",
    "\n",
    "    # with open(model_file, \"rb\") as f:\n",
    "    #     encoded = Binary(f.read())\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    # # creating other attributes\n",
    "    # model = [{ \"model\": model_file, 'name': \"MLP\", 'created_time': time.time()}]\n",
    "    # pipe.dl_loader(model, schema_name)\n",
    "    \n",
    "\n",
    "save_model_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m     model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[39m# pred_price = model.predict(3.0, 6.0, 10.0, 1.06, 1.579772, 0.0)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[39m# print(pred_price)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m load_model_to_db()\n",
      "Cell \u001b[0;32mIn[150], line 11\u001b[0m, in \u001b[0;36mload_model_to_db\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m json_data \u001b[39m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[39m# result = pipe.dl_getter('ml__MultiLayerPerceptron')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# # print(result)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# # print(result[0][\"model\"])\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# # pickled_model = json_data[result[0][\"model\"]]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# model = pickle.loads(result[0][\"model\"])\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# # print(model)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/pickle.py:1589\u001b[0m, in \u001b[0;36m_Unpickler.load_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1587\u001b[0m args \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39mpop()\n\u001b[1;32m   1588\u001b[0m func \u001b[39m=\u001b[39m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1589\u001b[0m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39mload_model(filepath, safe_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/pickle_utils.py:46\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     40\u001b[0m         f\u001b[39m.\u001b[39mwrite(serialized_model)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# When loading, direct import will work for most custom objects\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# though it will require get_config() to be implemented.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Some custom objects (e.g. an activation in a Dense layer,\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# serialized as a string by Dense.get_config()) will require\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m# a custom_object_scope.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39;49mload_model(filepath, safe_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/saving_lib.py:277\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    274\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    276\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/saving_lib.py:242\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 242\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    243\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/serialization_lib.py:508\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     compile_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompile_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m compile_config:\n\u001b[0;32m--> 508\u001b[0m         instance\u001b[39m.\u001b[39;49mcompile_from_config(compile_config)\n\u001b[1;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[1;32m    511\u001b[0m     record_object_after_deserialization(\n\u001b[1;32m    512\u001b[0m         instance, config[\u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    513\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/engine/training.py:3392\u001b[0m, in \u001b[0;36mModel.compile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[1;32m   3390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m   3391\u001b[0m     \u001b[39m# Create optimizer variables.\u001b[39;00m\n\u001b[0;32m-> 3392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/optimizers/legacy/optimizer_v2.py:984\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hyper:\n\u001b[1;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_hyper(name)\n\u001b[0;32m--> 984\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/optimizers/legacy/optimizer_v2.py:974\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[39m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_hyper\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "def load_model_to_db():\n",
    "    json_data = {}\n",
    "\n",
    "    result = pipe.dl_getter('ml__MultiLayerPerceptron')\n",
    "    # print(result)\n",
    "    # print(result[0][\"model\"])\n",
    "    # pickled_model = json_data[result[0][\"model\"]]\n",
    "    model = pickle.loads(result[0][\"model\"])\n",
    "    # print(model)\n",
    "\n",
    "    # model = joblib.load(\"test\")\n",
    "\n",
    "    # pred_price = model.predict(3.0, 6.0, 10.0, 1.06, 1.579772, 0.0)\n",
    "\n",
    "    # print(pred_price)\n",
    "\n",
    "load_model_to_db()\n",
    " \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Mar  8 2023, 04:29:24) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b996d74428cb98fb363d931233fbb38b0ce88b2e0e1a2ea6a636f62c3ef3ff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
