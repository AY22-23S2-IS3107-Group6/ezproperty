{
  "cells": [
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 1,
=======
      "execution_count": 20,
>>>>>>> origin/36-create-ml-to-predict-price
      "metadata": {
        "id": "--rnRL8WqNcl"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Grace's Projects\\ezproperty\\db\n",
            "c:\\Grace's Projects\\ezproperty\n",
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Loading 0 documents to data warehouse.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n",
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Loading 0 documents to data warehouse.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n"
=======
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/keith/Desktop/NUS/Y2S2/IS3107/Project/ezproperty/db\n",
            "/Users/keith/Desktop/NUS/Y2S2/IS3107/Project/ezproperty\n",
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load process to data warehouse failed.\n",
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Database | Query executed successfully.\n",
            "      district  floorRangeStart  floorRangeEnd  area  transactionDate  resale  \\\n",
            "4995       3.0              6.0           10.0  1.06         1.579772     0.0   \n",
            "4996       3.0             16.0           20.0  0.76         1.579772     0.0   \n",
            "4997       3.0             21.0           25.0  1.16         1.579772     0.0   \n",
            "4998       3.0              1.0            5.0  1.16         1.579772     0.0   \n",
            "4999       3.0             11.0           15.0  1.59         1.579772     0.0   \n",
            "\n",
            "        price  \n",
            "4995  2.84946  \n",
            "4996  2.25270  \n",
            "4997  3.30000  \n",
            "4998  3.05700  \n",
            "4999  4.26430  \n",
            "district           float64\n",
            "floorRangeStart    float64\n",
            "floorRangeEnd      float64\n",
            "area               float64\n",
            "transactionDate    float64\n",
            "resale             float64\n",
            "price              float64\n",
            "dtype: object\n",
            "(4500, 6) (500, 6) (4500,) (500,)\n",
            "Epoch 1/10\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 1.0843 - mae: 1.0843\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.8444 - mae: 0.8444\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.7170 - mae: 0.7170\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.6517 - mae: 0.6517\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.6065 - mae: 0.6065\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.5852 - mae: 0.5852\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.5676 - mae: 0.5676\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.5477 - mae: 0.5477\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.5197 - mae: 0.5197\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.5120 - mae: 0.5120\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4964 - mae: 0.4964\n",
            "(500, 6)\n",
            "test loss is 0.49642622470855713\n",
            "test accuracy is 0.49642622470855713\n",
            "Pipeline | ml__MultiLayerPerceptron   | Deleting data from data lake with _id.\n",
            "Deleted 1 entries from ml__MultiLayerPerceptron\n",
            "Pipeline | ml__MultiLayerPerceptron   | Delete process from data lake failed.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n"
>>>>>>> origin/36-create-ml-to-predict-price
          ]
        }
      ],
      "source": [
        "# Provided: notebook bootstrapping\n",
        "# Keras Models\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "\n",
<<<<<<< HEAD
        "# # Aditional Libs\n",
=======
        "# Aditional Libs\n",
>>>>>>> origin/36-create-ml-to-predict-price
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path) \n",
        "\n",
        "from warehouse import DataWarehouse\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('../..'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path) \n",
        "from db.etl import MultilayerPerceptronPipeline\n",
        "\n",
        "pipe = MultilayerPerceptronPipeline()\n",
<<<<<<< HEAD
        "schema_name = 'ml__MultiLayerPerceptron'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2tX966Pp3RJ",
        "outputId": "de61e052-3a68-4dbb-d897-967d57503b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to 'localhost' with user 'root'\n",
            "Database | Using database is3107g6.\n",
            "Database | Query executed successfully.\n",
            "      district  floorRangeStart  floorRangeEnd  area  transactionDate  resale  \\\n",
            "4995       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
            "4996       3.0             16.0           20.0  0.76         0.999336     0.0   \n",
            "4997       3.0              6.0           10.0  1.40         0.999336     0.0   \n",
            "4998       3.0             21.0           25.0  1.06         0.665311     0.0   \n",
            "4999       3.0             26.0           30.0  1.06         0.665311     0.0   \n",
            "\n",
            "      price  \n",
            "4995  2.273  \n",
            "4996  2.245  \n",
            "4997  4.110  \n",
            "4998  3.240  \n",
            "4999  3.280  \n",
            "district           float64\n",
            "floorRangeStart    float64\n",
            "floorRangeEnd      float64\n",
            "area               float64\n",
            "transactionDate    float64\n",
            "resale             float64\n",
            "price              float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "db = DataWarehouse()\n",
        "\n",
        "dataset = db.query('''\n",
        "    SELECT district, floorRangeStart, floorRangeEnd, area, transactionDate, resale, price FROM main__PropertyTransaction\n",
        "    LIMIT 5000\n",
        "''')\n",
        "\n",
        "\n",
        "# Data pre-processing to convert all to float and standardise magnitude\n",
        "df = pd.DataFrame(dataset)\n",
        "for column in df.columns:\n",
        "    if column == \"transactionDate\":\n",
        "        df[column] = pd.to_datetime(df[column])\n",
        "        df[column] = (df[column].max() - df[column]) / np.timedelta64(1,'Y')\n",
        "    if column == \"price\": # price is in millions\n",
        "        df[column] = df[column].astype(float) / 1e6\n",
        "    if column == \"area\": # area is in 100 square feet\n",
        "        df[column] = df[column].astype(float) / 100\n",
        "    else:\n",
        "        df[column] = df[column].astype(float)\n",
        "print(df.tail())\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7JpSZnuqNcm",
        "outputId": "dff17f3e-814f-4ced-ddc5-87ae9d681309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4500, 6) (500, 6) (4500,) (500,)\n"
          ]
        }
      ],
      "source": [
        "train = df.sample(frac=0.9,random_state=200)\n",
        "test = df.drop(train.index)\n",
        "\n",
        "X_train, Y_train = train[[column for column in df.columns if column != 'price']], train['price']\n",
        "X_test, Y_test = test[[column for column in df.columns if column != 'price']], test['price']\n",
        "\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsmgfY4FwjK1",
        "outputId": "d3595f59-b714-44c2-cc4e-57ee672502a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                448       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,875\n",
            "Trainable params: 8,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build model\n",
        "def build_mlp_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  return model\n",
        "\n",
        "mlp_model = build_mlp_model()\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZINq9ljyxOIh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeAeh1lzTud3",
        "outputId": "3fa691cb-dac9-43dd-bd3e-d6463874933d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "282/282 [==============================] - 1s 1ms/step - loss: 0.9210 - mae: 0.9210\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.6201 - mae: 0.6201\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.5216 - mae: 0.5216\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.4790 - mae: 0.4790\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.4894 - mae: 0.4894\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 0s 963us/step - loss: 0.4803 - mae: 0.4803\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 0s 951us/step - loss: 0.4556 - mae: 0.4556\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 0s 989us/step - loss: 0.4319 - mae: 0.4319\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 0s 952us/step - loss: 0.4609 - mae: 0.4609\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 0s 943us/step - loss: 0.4512 - mae: 0.4512\n"
          ]
        }
      ],
      "source": [
        "mlp_history = mlp_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQ0LWQXVzU-",
        "outputId": "dda7cdd3-9dc8-4b4e-8501-2bf0b2de2ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 977us/step - loss: 0.3710 - mae: 0.3710\n",
            "(500, 6)\n",
            "test loss is 0.37098559737205505\n",
            "test accuracy is 0.37098559737205505\n"
          ]
        }
      ],
      "source": [
        "loss, acc = mlp_model.evaluate(X_test, Y_test)\n",
        "print(X_test.shape)\n",
        "print(f'test loss is {loss}')\n",
        "print(f'test accuracy is {acc}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline | ml__MultiLayerPerceptron   | Loading 1 documents to data lake.\n"
          ]
        }
      ],
      "source": [
        "def save_model_to_db():\n",
=======
        "schema_name = 'ml__MultiLayerPerceptron'\n",
        "\n",
        "\n",
        "\n",
        "# Creates a new MLP and loads into datalake\n",
        "def __init__():\n",
        "    db = DataWarehouse()\n",
        "\n",
        "    dataset = db.query('''\n",
        "        SELECT district, floorRangeStart, floorRangeEnd, area, transactionDate, resale, price FROM main__PropertyTransaction\n",
        "        LIMIT 5000\n",
        "    ''')\n",
        "\n",
        "    # Data pre-processing to convert all to float and standardise magnitude\n",
        "    df = pd.DataFrame(dataset)\n",
        "    for column in df.columns:\n",
        "        if column == \"transactionDate\":\n",
        "            df[column] = pd.to_datetime(df[column])\n",
        "            df[column] = (df[column].max() - df[column]) / np.timedelta64(1,'Y')\n",
        "        if column == \"price\": # price is in millions\n",
        "            df[column] = df[column].astype(float) / 1e6\n",
        "        if column == \"area\": # area is in 100 square feet\n",
        "            df[column] = df[column].astype(float) / 100\n",
        "        else:\n",
        "            df[column] = df[column].astype(float)\n",
        "    print(df.tail())\n",
        "    print(df.dtypes)\n",
        "\n",
        "\n",
        "    # Splitting data into train and test\n",
        "    train = df.sample(frac=0.9,random_state=200)\n",
        "    test = df.drop(train.index)\n",
        "\n",
        "    X_train, Y_train = train[[column for column in df.columns if column != 'price']], train['price']\n",
        "    X_test, Y_test = test[[column for column in df.columns if column != 'price']], test['price']\n",
        "\n",
        "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "\n",
        "    # Building model with 3 hidden layers, each with 64 neurons\n",
        "    mlp_model = keras.Sequential()\n",
        "    mlp_model.add(Dense(6, activation='relu', input_shape=(6,)))\n",
        "    mlp_model.add(Dense(64, activation='relu'))\n",
        "    mlp_model.add(Dense(64, activation='relu'))\n",
        "    mlp_model.add(Dense(64, activation='relu'))\n",
        "    mlp_model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    mlp_model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
        "\n",
        "    # Train model\n",
        "    mlp_history = mlp_model.fit(X_train, Y_train, epochs=10, batch_size=16)\n",
        "\n",
        "    # Check accuracy and error\n",
        "    loss, acc = mlp_model.evaluate(X_test, Y_test)\n",
        "    print(X_test.shape)\n",
        "    print(f'test loss is {loss}')\n",
        "    print(f'test accuracy is {acc}')\n",
        "\n",
        "    # remove previous model\n",
        "    pipe.dl_delete_all(schema_name)\n",
>>>>>>> origin/36-create-ml-to-predict-price
        "\n",
        "    #pickling the model\n",
        "    pickled_model = pickle.dumps(mlp_model)\n",
        "    \n",
        "    # creating other attributes\n",
        "    model = [{ \"model\": pickled_model, 'name': \"MLP\", 'created_time': time.time()}]\n",
        "    pipe.dl_loader(model, schema_name)\n",
        "\n",
<<<<<<< HEAD
        "save_model_to_db()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n",
            "<keras.engine.sequential.Sequential object at 0x0000019F851F4940>\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "[[2.1240528]]\n"
          ]
        }
      ],
      "source": [
        "def load_from_db_and_predict(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale):\n",
        "    json_data = {}\n",
=======
        "\n",
        "\n",
        "# Retrieves MLP from Data Lake and predicts price \n",
        "def load_from_db_and_predict(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale):\n",
>>>>>>> origin/36-create-ml-to-predict-price
        "\n",
        "    result = pipe.dl_getter('ml__MultiLayerPerceptron')\n",
        "    model = pickle.loads(result[0][\"model\"])\n",
        "    print(model)\n",
        "\n",
        "    input_data  = np.array([[district, floorRangeStart, floorRangeEnd, area, transactionDate, resale]])\n",
        "    pred_price = model.predict(input_data)\n",
        "    print(pred_price)\n",
        "\n",
<<<<<<< HEAD
        "load_from_db_and_predict(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale)    "
      ]
=======
        "    # load_from_db_and_predict(3.0, 6.0, 10.0, 1.06, 1.579772, 0.0)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline | ml__MultiLayerPerceptron   | Retreiving data from data lake with _id.\n",
            "Pipeline | ml__MultiLayerPerceptron   | Load success. Retrieved 1 documents.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Adam' object has no attribute 'build'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# input_data  = np.array([[district, floorRangeStart, floorRangeEnd, area, transactionDate, resale]])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m# pred_price = model.predict(input_data)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# print(pred_price)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m load_from_db_and_predict(\u001b[39m3.0\u001b[39;49m, \u001b[39m6.0\u001b[39;49m, \u001b[39m10.0\u001b[39;49m, \u001b[39m1.06\u001b[39;49m, \u001b[39m1.579772\u001b[39;49m, \u001b[39m0.0\u001b[39;49m)    \n",
            "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mload_from_db_and_predict\u001b[0;34m(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_db_and_predict\u001b[39m(district, floorRangeStart, floorRangeEnd, area, transactionDate, resale):\n\u001b[1;32m      3\u001b[0m     result \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mdl_getter(\u001b[39m'\u001b[39m\u001b[39mml__MultiLayerPerceptron\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mloads(result[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(model)\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39mload_model(filepath, safe_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/pickle_utils.py:46\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     40\u001b[0m         f\u001b[39m.\u001b[39mwrite(serialized_model)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# When loading, direct import will work for most custom objects\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# though it will require get_config() to be implemented.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Some custom objects (e.g. an activation in a Dense layer,\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# serialized as a string by Dense.get_config()) will require\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m# a custom_object_scope.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39;49mload_model(filepath, safe_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/saving_lib.py:277\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    274\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    276\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/saving_lib.py:242\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 242\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    243\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/saving/serialization_lib.py:508\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     compile_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompile_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m compile_config:\n\u001b[0;32m--> 508\u001b[0m         instance\u001b[39m.\u001b[39;49mcompile_from_config(compile_config)\n\u001b[1;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[1;32m    511\u001b[0m     record_object_after_deserialization(\n\u001b[1;32m    512\u001b[0m         instance, config[\u001b[39m\"\u001b[39m\u001b[39mshared_object_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    513\u001b[0m     )\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/engine/training.py:3392\u001b[0m, in \u001b[0;36mModel.compile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[1;32m   3390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m   3391\u001b[0m     \u001b[39m# Create optimizer variables.\u001b[39;00m\n\u001b[0;32m-> 3392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/optimizers/legacy/optimizer_v2.py:984\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hyper:\n\u001b[1;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_hyper(name)\n\u001b[0;32m--> 984\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.9/site-packages/keras/optimizers/legacy/optimizer_v2.py:974\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[39m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_hyper\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
          ]
        }
      ],
      "source": []
>>>>>>> origin/36-create-ml-to-predict-price
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
<<<<<<< HEAD
      "version": "3.10.11"
=======
      "version": "3.9.16"
>>>>>>> origin/36-create-ml-to-predict-price
    },
    "vscode": {
      "interpreter": {
        "hash": "9b996d74428cb98fb363d931233fbb38b0ce88b2e0e1a2ea6a636f62c3ef3ff6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
